import json
import os.path
import pickle
import numpy as np
from os import system as sys
import subprocess
from src.SMTPEmail import SendEmail
from src.UserDatabase import UserData


def iso_prediction(X):
    """
    Makes prediction on keypoints generated by OpenPose on the user video submitted. Returns -1 or 1 if
    model predicts that the patient requires surgery or not. Returns decision function based on prediction.
    Returns score sample based on how far from the mean the keypoints are.

    :param X: Keypoint array generated by OpenPose.
    :return prediction: -1 predicting patient needs surgery. 1 prediction patient does not need surgery
    :return score: Decision function of prediction
    :return score_samp: Score sample of prediction
    """
    model = pickle.load(open("/home/ubuntu/gait_analysis_model_iso_ec2.sav", "rb"))
    prediction = model.predict(X)
    score = model.decision_function(X)
    score_samp = model.score_samples(X)

    return prediction, score, score_samp


def convert_json(path):
    """
    Converts JSON keypoints generated from OpenPose into a NumPy array to be used for predictions. Deletes
    confidence score generated by OpenPose.

    :param path: Path to the folder containing OpenPose generated JSON keypoint files.
    :return: Prediction made by iso_prediction function
    """
    key_point_list = []

    for filename in os.listdir(path):
        json_filename = path + "/" + filename
        with open(json_filename) as f:
            data_json = json.load(f)
        try:
            key_point_list.extend(data_json['people'][0]['pose_keypoints_2d'])
        except:
            key_point_list.extend([0] * 75)

    data = np.array(key_point_list)
    data = data[:3600]
    remove_data = [x for x in range(len(data)) if x % 3 == 2]
    data = np.delete(data, remove_data)
    data = data.reshape(1, -1)

    return iso_prediction(data)


class UserVideo:
    def __init__(self, filename):
        """
        Initialise class with user video filename

        :param filename: Uploaded video filename
        """
        self.filename = filename
        if "-atsymbol-" in filename and "-fullstop-" in filename:
            self.email = ".".join(filename.split(".")[:-1])
        else:
            self.email = None
        self.file = None
        self.num_splits = None
        self.prediction_arr = []
        self.score_arr = []
        self.sample_arr = []

    def check_emails(self):
        """
        Checks whether email entered by user is in database of users. If so, changes filename
        uploaded to the original filename plus a time ID.
        """
        userdata = UserData(self.email)
        user_file = userdata.find_file()
        if user_file:
            _, file_ext = os.path.splitext(f"/home/ubuntu/processing/{self.filename}")
            sys(f"mv /home/ubuntu/processing/{self.email}{file_ext} /home/ubuntu/data/{user_file}{file_ext}")
            self.filename = user_file + file_ext

    def process(self):
        """
        Removes extension from uploaded file to just get filename.
        """
        self.file = ".".join(self.filename.split(".")[:-1])
        sys(f"mkdir /home/ubuntu/data/output/poses/{self.file}")

    def split_video(self):
        """
        Normalises video to 24 fps. Gets uploaded video duration and splits video into x 2 second segements.
        Removes original uploaded file from EC2 instance.
        """
        # Normalises video
        sys(f"docker run -v /home/ubuntu/data:/data --rm --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=0 "
            f"darrengebler/weko-openpose-aws ffmpeg -i ../data/{self.filename} -filter:v fps=fps=24 ../data/output.mp4")

        # Gets video duration
        video = subprocess.check_output(f"docker run -v /home/ubuntu/data:/data --rm --runtime=nvidia -e "
                                        f"NVIDIA_VISIBLE_DEVICES=0 darrengebler/weko-openpose-aws ffprobe -v error "
                                        f"-select_streams v:0 -show_entries stream=duration -of "
                                        f"default=noprint_wrappers=1:nokey=1 ../data/output.mp4", shell=True)
        video_duration = float(video.rstrip().decode())
        video_duration = int(video_duration)

        # Splits video into 2 second segements
        for i in range(1, video_duration - 2):
            sys(f"docker run -v /home/ubuntu/data:/data --rm --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=0 "
                f"darrengebler/weko-openpose-aws ffmpeg -i ../data/output.mp4 -ss 00:00:{i} -t 00:00:02 "
                f"../data/output_{i}.mp4")
            sys(f"mkdir /home/ubuntu/data/output/poses/{self.file}/{i}")

        # Removes original file from EC2 instance
        sys(f"rm /home/ubuntu/data/{self.filename}")

        self.num_splits = video_duration

    def openpose_splits(self):
        """
        Runs OpenPose on all split videos created in split_video function and stores keypoints in
        their respective folders. Calls convert_json function to make prediction on keypoints generated.
        """
        for i in range(1, self.num_splits - 2):
            sys(f"docker run -v /home/ubuntu/data:/data --rm --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=0 "
                f"darrengebler/weko-openpose-aws ./build/examples/openpose/openpose.bin --video "
                f"../data/output_{i}.mp4 --write_json ../data/output/poses/{self.file}/{i} --display 0 --render_pose 0")
            sys(f"rm /home/ubuntu/data/output_{i}.mp4")
            prediction, score, sample = convert_json(f"/home/ubuntu/data/output/poses/{self.file}/{i}")
            self.prediction_arr.append(prediction)
            self.score_arr.append(score)
            self.sample_arr.append(sample)

    def write_to_text(self):
        """
        Writes prediction scores to text file. Used to upload back to AWS S3. Calls average_score function to
        calculate average prediction, decision function and score sample.

        :return: -1 if prediction average thinks walking is abnormal. 0 if prediction average thinks walking is normal.
                    Used to store keypoints respective folders in S3 bucket.
        """
        results = self.average_score()
        output_txt = open(f"/home/ubuntu/data/output/{self.file}.txt", "a+")
        for i in range(len(self.prediction_arr)):
            predict = [
                "Prediction {}: {} (1 means no surgery, -1 means needs surgery)\n".format(i,
                                                                                          str(self.prediction_arr[i])),
                "Decision Function Score {} of {}\n".format(i, self.score_arr[i]),
                "Score sample {} of {}\n\n".format(i, self.sample_arr[i])]
            output_txt.writelines(predict)
        averages = [f"Average Prediction {results[0]}\n",
                    f"Average Decision Function Score {results[1]}\n",
                    f"Average Score Sample {results[2]}"]
        output_txt.writelines(averages)
        output_txt.close()

        return -1 if results[0] < 0.1 else 0

    def average_score(self):
        """
        Calculates the average prediction, decision function and score based on model output.

        :return avg_prediction: Average prediction
        :return avg_scores: Average decision function
        :return avg_score_samples: Average score sample
        """
        try:
            avg_prediction = sum(self.prediction_arr) / len(self.prediction_arr)
            avg_scores = sum(self.score_arr) / len(self.score_arr)
            avg_score_samples = sum(self.sample_arr) / len(self.sample_arr)
        except:
            avg_prediction = 0
            avg_scores = 0
            avg_score_samples = 0

        return avg_prediction, avg_scores, avg_score_samples

    def writing_video(self):
        """
        Overlays OpenPose generated keypoints over users original video.

        :return: Filename of generated video.
        """
        sys(f"docker run -v /home/ubuntu/data:/data --rm --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=0 "
            f"darrengebler/weko-openpose-aws ./build/examples/openpose/openpose.bin --video "
            f"../data/output.mp4 --write_video ../data/{self.file}_keypoints.avi --display 0")

        return f"{self.file}_keypoints.avi"

    def upload_s3(self, predict):
        """
        Uploads generated video made in writing_video function. Zips and uploads keypoints generated in openpose_splits
        function. Uploads text file generated from write_to_text function.

        :param predict: -1 if patient predicted to require surgery, 0 if predicted not to require surgery
        """
        sys(f"aws s3 cp /home/ubuntu/data/{self.file}_keypoints.avi "
            f"s3://gait-analysis/output_videos/{self.file}_keypoints.avi")
        sys(f"docker run -v /home/ubuntu/data:/data --rm --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=0 "
            f"darrengebler/weko-openpose-aws zip -r ../data/{self.file}.zip ../data/output/poses/{self.file}")

        if predict == -1:
            sys(f"aws s3 cp /home/ubuntu/data/{self.file}.zip"
                f" s3://gait-analysis/output_keypoints_abnormal/{self.file}.zip")
        else:
            sys(f"aws s3 cp /home/ubuntu/data/{self.file}.zip s3://gait-analysis/output_keypoints/{self.file}.zip")

        sys(f"aws s3 cp /home/ubuntu/data/output/{self.file}.txt s3://gait-analysis/output/{self.file}.txt")

    def clean_up(self):
        """
        Deletes EC2 files and folders that were created by script.
        """
        sys("rm /home/ubuntu/data/output.mp4")
        sys(f"rm /home/ubuntu/data/{self.file}_keypoints.avi")
        sys(f"rm -r /home/ubuntu/data/output/poses/{self.file}/")
        sys(f"rm /home/ubuntu/data/output/{self.file}.txt")
        sys(f"rm /home/ubuntu/data/{self.file}.zip")


def download_videos():
    """
    Main function of script. Downloads videos from S3 bucket and begins analysing each video if there are videos in the
    bucket. If no videos present, EC2 will shutdown.

    :return: False if no videos are in processing folder.
    """

    # Download videos from S3 bucket and stores in processing folder
    sys("aws s3 cp s3://gait-analysis/processing /home/ubuntu/processing --recursive")

    # Gets files in processing folder
    filenames = os.listdir("/home/ubuntu/processing")

    if not filenames:
        return False

    # Loop through files in directory
    for filename in filenames:
        # Initialise UserVideo class with downloaded video
        user_vid = UserVideo(filename)

        # Checks if filename is an email.
        if user_vid.email:
            user_vid.check_emails()
        else:
            sys(f"mv /home/ubuntu/processing/{filename} /home/ubuntu/data/{filename}")

        # Remove file from S3
        sys(f"aws s3 rm s3://gait-analysis/processing/{filename}")

        # Process Video
        user_vid.process()

        # Split video into 2 second segments
        user_vid.split_video()

        # Runs OpenPose on split videos
        user_vid.openpose_splits()

        # Generates a prediction score and writes to text
        prediction_score = user_vid.write_to_text()

        # Generates file with OpenPose keypoints overlayed
        file = user_vid.writing_video()

        # If filename is a user email, send email to user with video link.
        if user_vid.email:
            email_send = SendEmail(file, user_vid.email)
            email_send.write_email()

        # Upload generated files to s3
        user_vid.upload_s3(prediction_score)

        # Removes generated files from EC2
        user_vid.clean_up()


# Loops while videos are downloaded from S3 bucket
while True:
    if not download_videos():
        break

# Shutdown if no videos in S3 bucket.
sys("shutdown now")
